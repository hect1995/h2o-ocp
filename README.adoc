= H2O Operator Openshift 4
Héctor Esteban Cabezos <hesteban@redhat.com>
v1.0, 2020-11
// Create TOC wherever needed
:toc: macro
:sectanchors:
:sectnumlevels: 2
:sectnums: 
:source-highlighter: pygments
:imagesdir: images
// Start: Enable admonition icons
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
ifndef::env-github[]
:icons: font
endif::[]
// End: Enable admonition icons

This repository demonstrates some of the basic features of deploying a H2O operator on OCP4 and the use of the Monitoring stack. 

// Create the Table of contents here
toc::[]

== Launch H2O

The first step is to define the `OperatorGroup`, which selects target namespaces in which to generate required RBAC access for its member Operators, and a `Subscription` to subscribe a namespace to an Operator. The `h2o-01-operator.yaml` template does all that:

[source, bash]
----
OPERATOR_NAMESPACE=h2o-opertaor # Define the namespace
$ oc process -f templates/h2o-01-operator.yaml -p OPERATOR_NAMESPACE=${OPERATOR_NAMESPACE} | oc apply -f -
----

At this point, OLM is now aware of the selected Operator. A cluster service version (CSV) for the Operator should appear in the target namespace, and APIs provided by the Operator should be available for creation.
Let's check it:

[source, bash]
----
$ oc get crd -n ${OPERATOR_NAMESPACE}| grep "h2o"
h2os.h2o.ai             2021-04-19T11:32:49Z

$ oc describe crd h2os.h2o.ai
Name:         h2os.h2o.ai
Namespace:    
Labels:       operators.coreos.com/h2o-operator.h2o-operator1=
Annotations:  <none>
API Version:  apiextensions.k8s.io/v1
Kind:         CustomResourceDefinition
Metadata:
  Creation Timestamp:  2021-04-19T11:32:49Z
  Generation:          1
  Managed Fields:
    API Version:  apiextensions.k8s.io/v1beta1
    Fields Type:  FieldsV1
    ...
Spec:
  Conversion:
    Strategy:  None
  Group:       h2o.ai
  Names:
    Kind:                   H2O
    List Kind:              H2OList
    Plural:                 h2os
    Singular:               h2o
  Preserve Unknown Fields:  true
  Scope:                    Namespaced
  Versions:
    Name:  v1beta
    Schema:
      openAPIV3Schema:
        Properties:
          Spec:
            One Of:
              Required:
                version
              Required:
                customImage
            Properties:
              Custom Image:
                Properties:
                  Command:
                    Type:  string
                  Image:
                    Type:  string
                Required:
                  image
                Type:  object
              Nodes:
                Type:  integer
              Resources:
                Properties:
                  Cpu:
                    Minimum:  1
                    Type:     integer
                  Memory:
                    Pattern:  ^([+-]?[0-9.]+)([eEinumkKMGTP]*[-+]?[0-9]*)$
                    Type:     string
                  Memory Percentage:
                    Maximum:  100
                    Minimum:  1
                    Type:     integer
                Required:
                  cpu
                  memory
                Type:  object
              Version:
                Type:  string
            Required:
              nodes
              resources
            Type:  object
          Status:
            Type:  object
        Type:      object
    Served:        true
    Storage:       true
    Subresources:
      Status:
Status:
  Accepted Names:
    Kind:       H2O
    List Kind:  H2OList
    Plural:     h2os
    Singular:   h2o
  Conditions:
    ...
  Stored Versions:
    v1beta
----

Now, a CR of kind `H2O` can be deployed into the namespace:

[source, bash]
----
$ oc process -f templates/h2o-02-instance.yaml -p OPERATOR_NAMESPACE=${OPERATOR_NAMESPACE} | oc apply -f -
----

Once the instance is deployed, a `route` needs to be created to expose the service(`svc`)

[source, bash]
----
$ oc expose svc/h2o-test -n ${OPERATOR_NAMESPACE}
----

By executing `oc get routes` we can copy the route create it and access the GUI of H2o in our desired navigation explorer.

=== References

- https://www.h2o.ai/blog/accelerate-machine-learning-workflows-with-h2o-ai-driverless-ai-on-red-hat-openshift-enterprise-kubernetes-platform/


== Monitoring
A typical OpenShift monitoring stack includes Prometheus for monitoring both systems and services, and Grafana for analyzing and visualizing metrics.

Administrators are often looking to write custom queries and create custom dashboards in Grafana. However, Grafana instances provided with the monitoring stack (and its dashboards) are read-only. To solve this problem, we can use the community-powered Grafana operator provided by OperatorHub. I will follow the implementation accurately explained https://github.com/alvarolop/rhdg8-server#4-monitoring-rhdg-with-grafana)[here].

As with the H2O operator, we first need to subscribe and deploy the operator using the following template:

[source, bash]
----
OPERATOR_NAMESPACE="grafana"
$ oc process -f templates/grafana-01-operator.yaml -p OPERATOR_NAMESPACE=${OPERATOR_NAMESPACE}| oc apply -f -
----

Now, a Grafana instance is created using the operator:

[source, bash]
----
oc process -f templates/grafana-02-instance.yaml -p OPERATOR_NAMESPACE=${OPERATOR_NAMESPACE}| oc apply -f
----

A `GrafanaDataSource`, that points to the Prometheus metrics, is created:

[source, bash]
----
oc adm policy add-cluster-role-to-user cluster-monitoring-view -z grafana-serviceaccount -n ${OPERATOR_NAMESPACE}
BEARER_TOKEN=$(oc serviceaccounts get-token grafana-serviceaccount -n ${OPERATOR_NAMESPACE})
oc process -f templates/grafana-03-datasource.yaml -p BEARER_TOKEN=${BEARER_TOKEN} | oc apply -f -
----

And finally the Grafana dashboard is to be created:

[source, bash]
----
DASHBOARD_NAME="grafana-dashboard-h2o"
# Create a configMap containing the Dashboard
oc create configmap $DASHBOARD_NAME --from-file=dashboard=grafana/$DASHBOARD_NAME.json -n ${OPERATOR_NAMESPACE}
# Create a Dashboard object that automatically updates Grafana
oc process -f templates/grafana-04-dashboard.yaml -p DASHBOARD_NAME=$DASHBOARD_NAME | oc apply -f -
----

=== References

- https://github.com/alvarolop/rhdg8-server

== Alert Manager

The Alertmanager manages incoming alerts; this includes silencing, inhibition, aggregation, and sending out notifications through methods such as email, PagerDuty, and HipChat. 

An implementation example through `email` is given in in [templates/alertmanager/alertmanager.yaml](templates/alertmanager/alertmanager.yaml).

NOTE: You need to create an [App Password](https://support.google.com/accounts/answer/185833?hl=en). To do that, go to **Account Settings -> Security -> Signing in to Google -> App password** (if you don’t see App password as an option, you probably haven’t set up 2-Step Verification and will need to do that first). Copy the newly-created password.

The Alertmanager configuration can be updated replacing the content of the alertmanager-main `Secret`.

[source, bash]
----
$ oc create secret generic alertmanager-main \
    --from-file=templates/alertmanager/alertmanager.yml \
        --dry-run -o=yaml -n openshift-monitoring |\
            oc replace secret --filename=- -n openshift-monitoring
----

Moreover, We can configure the Alertmanager through the Openshift 4 platform, in **Administration -> Cluster Settings -> Global configuration -> Alertmanager**

image::ocp_alertmanager_gui.png[]

If everything works as expected the receiver should receive notifications like the following one:

image::alert_manager_notification.png[]

=== References

- https://github.com/samuelvl/ocp4-upi-baremetal-lab/tree/master/day-two/04-monitoring#alertmanager
- https://grafana.com/blog/2020/02/25/step-by-step-guide-to-setting-up-prometheus-alertmanager-with-slack-pagerduty-and-gmail/